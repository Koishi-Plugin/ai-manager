# koishi-plugin-ai-manager

[![npm](https://img.shields.io/npm/v/koishi-plugin-ai-manager?style=flat-square)](https://www.npmjs.com/package/koishi-plugin-ai-manager)

基于大型语言模型的全自动群组消息审查插件。它能够将消息汇总后发送至模型进行分析，并根据预设规则，自动对违规消息执行撤回、转发操作，或对违规用户进行禁言。

---

## ✨ 功能特性

- **🚀 两种审查模式**：支持**实时模式**（每条消息独立分析）和**智能批处理模式**，后者可将多条消息打包一次性发送给 AI，显著降低 API 调用频率，节约成本。
- **🔌 通用 API 支持**：支持对接所有兼容 OpenAI `chat/completions` API 格式的语言模型服务。
- **📝 高度自定义规则**：通过自定义 `Rule` (规则)，您可以精确地告诉 AI 需要审查哪些内容，无论是广告、不当言论还是其他违规行为。
- **⚙️ 灵活的自动化操作**：可自由组合**撤回消息**、**禁言用户**（支持自定义时长）、**转发违规证据**到指定频道等多种操作。
- **🛠️ 丰富的配置选项**：支持配置白名单用户、批处理大小、批处理最大等待时间等参数，满足不同场景下的精细化管理需求。
- **🐛 内置调试模式**：一键开启 Debug 模式，轻松查看发送给 AI 的原始请求和收到的原始响应，极大地方便了规则调试和问题排查。

## ⚙️ 配置项说明

### 1. 模型配置

此部分用于配置您所使用的大语言模型服务。

| 配置项 | 类型 | 默认值 | 说明 |
| :--- | :--- | :--- | :--- |
| `Endpoint` | `string` | - | **必需**。您的 AI 服务端点，必须兼容 OpenAI 的 `/v1/chat/completions` 格式。例如 `https://api.openai.com/v1`。 |
| `ApiKey` | `string` | - | **必需**。您的 AI 服务密钥 (API Key)。 |
| `Model` | `string` | - | 您希望使用的模型名称，例如 `gpt-4o`、`glm-4` 等。 |
| `Rule` | `text` | - | **核心功能**。您为 AI 制定的审查规则，请用自然语言清晰描述，AI 将严格按照此规则进行判断。 |
| `Debug` | `boolean` | `false` | 启用调试模式。开启后，将在控制台以 `debug` 等级输出发送给 AI 的完整请求体和收到的原始响应体。 |

### 2. 审查操作

此部分用于配置检测到违规行为后需要执行的操作。

| 配置项 | 类型 | 默认值 | 说明 |
| :--- | :--- | :--- | :--- |
| `Action` | `checkbox` | `[]` (无) | 选择要执行的操作，可多选：`recall` (撤回)，`mute` (禁言)，`forward` (转发)。 |
| `Target` | `string` | `onebot:123456789` | 如果选择了 `forward`，违规消息将会被作为合并转发消息发送到这个目标。格式为 `平台名:频道/群组ID`。 |

### 3. 消息配置

此部分用于配置消息的审查与批处理行为。

| 配置项 | 类型 | 默认值 | 说明 |
| :--- | :--- | :--- | :--- |
| `batchMode` | `boolean` | `false` | 是否启用消息批处理模式。关闭时，每条消息都会被独立、实时地进行审查。 |
| `maxBatchSize` | `number` | `128` | **[批处理模式]** 一个批次中最多包含的消息数量。达到此数量将立即触发一次 AI 分析。 |
| `maxBatchTime` | `number` | `600` | **[批处理模式]** (单位: 秒) 一个批次最长的等待时间。若批次中第一条消息的等待时间超过此值，即使未达到最大数量，当前批次也将被发送分析。 |
| `whitelist` | `string[]`| `['2854196310']` | 白名单用户ID列表。这些用户的消息将被插件完全忽略，不进行审查。 |
